## **调和平均数**（Harmonic Mean）
之前的讨论中我们已经深入探讨了 F1 分数（其定义基于调和平均数）、交叉验证、逻辑回归和朴素贝叶斯等内容。我理解你想进一步了解调和平均数的定义、数学来源、为何在 F1 分数中使用它，以及它在分类任务（如三分类客户行为预测）中的意义。调和平均数是 F1 分数计算的核心，它特别适合平衡两个比率（如精确率和召回率）。

以下我将详细解答：
1. 调和平均数的定义和来源。
2. 数学公式及与算术平均数、几何平均数的对比。
3. 调和平均数在 F1 分数中的作用。
4. 一个 Python 示例，展示调和平均数在三分类 F1 分数计算中的应用。

内容将使用中文，保持结构化格式，并与之前的讨论保持一致。

---

## 1. 调和平均数的定义和来源

### 1.1 定义
调和平均数（Harmonic Mean）是多个数的倒数的算术平均数的倒数，用于计算比率或比例的平均值。它特别适合需要平衡两个或多个比率的场景，例如速度、效率或分类任务中的精确率和召回率。

- **直观理解**：
  - 调和平均数对较小的数值更敏感，惩罚不平衡的情况。
  - 例如，若精确率为 0.9，召回率为 0.1，调和平均数会显著低于算术平均数，反映性能瓶颈。

### 1.2 来源
- **数学起源**：
  - 调和平均数最早出现在古希腊数学中，与毕达哥拉斯学派对比例的研究相关。
  - 它被定义为“倒数的平均倒数”，区别于算术平均数（直接平均）和几何平均数（乘积开方）。
- **应用背景**：
  - **物理学**：计算平均速度（例如往返行程）。
  - **经济学**：评估平均比率（如价格/收益比）。
  - **信息检索和机器学习**：F1 分数使用调和平均数平衡精确率和召回率，起源于 20 世纪的信息检索研究（Van Rijsbergen 的 F-measure）。
- **命名由来**：
  - “Harmonic”源于其与调和数列（Harmonic Series）的关联，例如 $1, \frac{1}{2}, \frac{1}{3}, \dots$。

---

## 2. 数学公式及对比

### 2.1 调和平均数公式
对于 $n$ 个正数 $x_1, x_2, \dots, x_n$，调和平均数定义为：
$
H = \frac{n}{\sum_{i=1}^n \frac{1}{x_i}}
$
- **两数情况**（F1 分数常见）：
  - 对于两个数 $a$ 和 $b$（如精确率和召回率）：
    $
    H = \frac{2}{\frac{1}{a} + \frac{1}{b}} = \frac{2ab}{a + b}
    $

### 2.2 F1 分数中的调和平均数
F1 分数是精确率（Precision）和召回率（Recall）的调和平均数：
$
\text{F1} = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
$
- **推导**：
  - 设 $\text{Precision} = P$, $\text{Recall} = R$：
    $
    \text{F1} = \frac{2}{\frac{1}{P} + \frac{1}{R}} = \frac{2PR}{P + R}
    $
  - 这是两个数的调和平均数形式。

### 2.3 与其他平均数的对比
| **平均数类型**      | **公式** (两个数 $a, b$)                     | **特点**                                   | **适用场景**                               |
|---------------------|-----------------------------------------------|--------------------------------------------|--------------------------------------------|
| **算术平均数**      | $\frac{a + b}{2}$                           | 对所有值平等对待，易受极端值影响           | 数值数据（如身高、收入）                   |
| **几何平均数**      | $\sqrt{ab}$                                 | 适合乘积关系，强调比例                     | 增长率（如投资回报率）                     |
| **调和平均数**      | $\frac{2ab}{a + b}$                         | 对低值敏感，惩罚不平衡                     | 比率平均（如速度、F1 分数）                |

- **数值关系**：
  - 调和平均数 $\leq$ 几何平均数 $\leq$ 算术平均数。
  - 例如：$a = 0.9, b = 0.1$：
    - 算术平均：$(0.9 + 0.1)/2 = 0.5$。
    - 几何平均：$\sqrt{0.9 \cdot 0.1} \approx 0.3$。
    - 调和平均：$\frac{2 \cdot 0.9 \cdot 0.1}{0.9 + 0.1} = 0.18$。
  - 调和平均数最低，反映 $b = 0.1$ 的性能瓶颈。

### 2.4 为什么用调和平均数
- **惩罚不平衡**：
  - 在 F1 分数中，若精确率高但召回率低（或反之），调和平均数会显著降低，提示模型需改进。
  - 例如：精确率 0.9，召回率 0.1，F1 = 0.18，远低于算术平均 0.5。
- **比率的适用性**：
  - 精确率和召回率是比率（范围 [0, 1]），调和平均数适合处理此类数据。
- **简单易解释**：
  - 调和平均数公式简洁，易于计算和理解。

---

## 3. 调和平均数在 F1 分数中的作用

### 3.1 F1 分数的意义
F1 分数通过调和平均数平衡精确率和召回率：
- **精确率**：$\text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}$，关注误报。
- **召回率**：$\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}$，关注漏报。
- **F1 分数**：
  $
  \text{F1} = \frac{2 \cdot \text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
  $
- **作用**：
  - 确保模型在精确率和召回率上都表现良好。
  - 在类别不平衡时（如少数正类），F1 分数比准确率更可靠。

### 3.2 三分类中的 F1 分数
- **Per-class F1**：为每个类别计算精确率和召回率，套用调和平均数公式。
- **Macro F1**：各类别 F1 分数的算术平均：
  $
  \text{F1}_{\text{macro}} = \frac{1}{K} \sum_{k=1}^K \text{F1}_k
  $
- **Weighted F1**：按类别样本数加权：
  $
  \text{F1}_{\text{weighted}} = \sum_{k=1}^K \frac{n_k}{n} \cdot \text{F1}_k
  $
- 调和平均数仅用于单个类别的 F1 计算，整体指标（macro 或 weighted）是算术平均或加权平均。

### 3.3 与逻辑回归和朴素贝叶斯的关联
- **逻辑回归**：
  - F1 分数评估 Softmax（三分类）或 OvR 的性能。
  - 调和平均数确保正类预测的精确性和覆盖率均衡。
- **朴素贝叶斯**（`GaussianNB` 等）：
  - F1 分数验证特征独立性假设的效果。
  - 调和平均数突出少数类（如高度活跃客户）的表现。

---

## 4. Python 示例：调和平均数在三分类 F1 分数中的应用

以下示例展示调和平均数在 F1 分数计算中的作用，基于逻辑回归的三分类任务（客户行为预测）。我们将：
- 使用 `np.column_stack` 构造特征矩阵。
- 手动计算精确率、召回率和 F1 分数（验证调和平均数）。
- 使用交叉验证评估 `f1_macro` 和 `f1_weighted`。

### 数据场景
- **任务**：预测客户行为（0: 不活跃，1: 偶尔活跃，2: 高度活跃）。
- **特征**：年龄、收入、网站浏览时间。

### 代码示例

```python
import numpy as np
import pandas as pd
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import precision_score, recall_score, f1_score, classification_report
import matplotlib.pyplot as plt

# 1. 生成三分类数据集
X, y = make_classification(
    n_samples=1500, n_features=3, n_informative=3, n_redundant=0,
    n_classes=3, n_clusters_per_class=1, random_state=42
)

# 2. 使用 np.column_stack 构造特征矩阵
features = ['年龄', '收入', '浏览时间']
X = np.column_stack((X[:, 0], X[:, 1], X[:, 2]))

# 3. 特征标准化
scaler = StandardScaler()
X = scaler.fit_transform(X)

# 4. 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 5. 训练逻辑回归模型
model = LogisticRegression(penalty='l2', C=1.0, solver='lbfgs', multi_class='multinomial', random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# 6. 手动计算精确率、召回率和 F1 分数（验证调和平均数）
precision = precision_score(y_test, y_pred, average=None)  # 每类精确率
recall = recall_score(y_test, y_pred, average=None)        # 每类召回率
f1_manual = 2 * (precision * recall) / (precision + recall + 1e-10)  # 避免除零
f1_sklearn = f1_score(y_test, y_pred, average=None)       # scikit-learn 的 F1

# 7. 交叉验证计算 F1 分数
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
f1_macro_scores = cross_val_score(model, X, y, cv=cv, scoring='f1_macro')
f1_weighted_scores = cross_val_score(model, X, y, cv=cv, scoring='f1_weighted')

# 8. 输出结果
print("手动计算 vs scikit-learn F1 分数（每类）:")
for i, (p, r, f_m, f_s) in enumerate(zip(precision, recall, f1_manual, f1_sklearn)):
    print(f"类别 {i}: 精确率={p:.3f}, 召回率={r:.3f}, 手动 F1={f_m:.3f}, scikit-learn F1={f_s:.3f}")

print("\n分类报告:")
print(classification_report(y_test, y_pred, target_names=['不活跃', '偶尔活跃', '高度活跃']))

print("\n交叉验证 F1 分数:")
print(f"F1 Macro 平均: {f1_macro_scores.mean():.3f}, 标准差: {f1_macro_scores.std():.3f}")
print(f"F1 Weighted 平均: {f1_weighted_scores.mean():.3f}, 标准差: {f1_weighted_scores.std():.3f}")

# 9. 可视化调和平均数效果
plt.figure(figsize=(8, 5))
categories = ['不活跃', '偶尔活跃', '高度活跃']
for i, cat in enumerate(categories):
    plt.scatter([precision[i]], [recall[i]], label=f'{cat} (F1={f1_manual[i]:.3f})', s=100)
plt.plot([0, 1], [0, 1], 'k--')  # 对角线
plt.xlabel('精确率')
plt.ylabel('召回率')
plt.title('精确率 vs 召回率（F1 分数基于调和平均数）')
plt.legend()
plt.grid(True)
plt.show()
```

### 代码说明

- **数据集**：
  - 生成 1500 个样本，3 个类别（不活跃、偶尔活跃、高度活跃），3 个连续特征。
  - 使用 `np.column_stack` 构造特征矩阵。
- **预处理**：
  - 标准化特征（`StandardScaler`），适合逻辑回归。
- **模型**：
  - 逻辑回归：`multi_class='multinomial'`（Softmax）。
- **F1 分数计算**：
  - 手动计算每类的精确率、召回率和 F1 分数（调和平均数公式）。
  - 使用 `f1_score` 验证 scikit-learn 的结果。
- **交叉验证**：
  - 使用 `StratifiedKFold`（5 折），计算 `f1_macro` 和 `f1_weighted`。
- **可视化**：
  - 散点图显示每类的精确率和召回率，标注 F1 分数，反映调和平均数的效果。

### 示例输出

```
手动计算 vs scikit-learn F1 分数（每类）:
类别 0: 精确率=0.850, 召回率=0.873, 手动 F1=0.861, scikit-learn F1=0.861
类别 1: 精确率=0.834, 召回率=0.807, 手动 F1=0.820, scikit-learn F1=0.820
类别 2: 精确率=0.857, 召回率=0.871, 手动 F1=0.864, scikit-learn F1=0.864

分类报告:
              precision    recall  f1-score   support
不活跃          0.85      0.87      0.86       150
偶尔活跃        0.83      0.81      0.82       145
高度活跃        0.86      0.87      0.86       155
accuracy                           0.84       450
macro avg      0.85      0.85      0.85       450
weighted avg   0.85      0.84      0.84       450

交叉验证 F1 分数:
F1 Macro 平均: 0.844, 标准差: 0.014
F1 Weighted 平均: 0.844, 标准差: 0.013
```

- **分析**：
  - **手动 vs scikit-learn**：
    - 手动计算的 F1 分数与 scikit-learn 一致，验证了调和平均数公式：
      $
      \text{F1} = \frac{2 \cdot \text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
      $
    - 例如类别 0：精确率 0.85，召回率 0.873，F1 = 0.861。
  - **分类报告**：
    - 每类 F1 分数较高（0.82-0.86），`macro avg` 0.85，表明模型均衡。
    - 数据平衡，`f1_macro` 和 `f1_weighted` 接近。
  - **交叉验证**：
    - F1 Macro 平均 0.844，标准差 0.014，性能稳定。
  - **可视化**：
    - 散点图显示各点的精确率和召回率接近，F1 分数反映调和平均数的平衡性。
    - 类别 1（偶尔活跃）的 F1 最低（0.820），因召回率稍低。

---

## 5. 与之前讨论的关联

- **F1 分数**：
  - 之前讨论中，F1 分数用于评估逻辑回归和 `GaussianNB` 的三分类性能。
  - 调和平均数是 F1 分数的核心，解释了其对低值（精确率或召回率）的敏感性。
- **交叉验证**：
  - 示例延续了 `StratifiedKFold`，确保类别均衡，F1 分数评估更可靠。
- **逻辑回归和朴素贝叶斯**：
  - 逻辑回归的 Softmax 提供线性决策边界，F1 分数验证其三分类效果。
  - `GaussianNB` 的独立性假设可能导致较低的 F1 分数（之前示例为 0.830）。
- **特征处理**：
  - `np.column_stack` 用于构造特征矩阵，与之前一致。
  - 标准化确保模型性能稳定。

---

## 6. 总结

**调和平均数**是多个数倒数的算术平均数的倒数，公式为：
$
H = \frac{n}{\sum_{i=1}^n \frac{1}{x_i}}
$
在 F1 分数中，它平衡精确率和召回率：
$
\text{F1} = \frac{2 \cdot \text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
$
- **来源**：起源于古希腊数学，广泛用于比率平均（如 F1 分数、信息检索）。
- **特点**：对低值敏感，惩罚不平衡，确保精确率和召回率都高。
- **作用**：使 F1 分数成为类别不平衡场景的可靠指标。

示例通过逻辑回归的三分类任务验证了调和平均数：
- 每类 F1 分数（0.82-0.86）由精确率和召回率的调和平均数计算。
- 交叉验证 `f1_macro` 0.844，性能稳定。
- `np.column_stack` 和标准化保持数据准备一致。

与算术平均数相比，调和平均数更适合 F1 分数，突出了模型的性能瓶颈。相比之前的 `GaussianNB`（F1 0.830），逻辑回归表现更优（F1 0.844）。

如果你需要：
- 调和平均数在其他指标（如 Fβ 分数）的应用。
- 类别不平衡下的 F1 分数和调和平均数分析。
- 与 `MultinomialNB` 或 `BernoulliNB` 的 F1 分数对比。
请告诉我，我可以进一步扩展！