## **交叉验证**（Cross-Validation），

以下我将详细介绍：
1. 交叉验证的原理和常见类型。
2. 在 scikit-learn 中实现交叉验证（结合逻辑回归和朴素贝叶斯）。
3. 一个完整的 Python 示例，展示交叉验证在三分类任务中的应用（延续客户行为分类场景）。
4. 与之前讨论的关联（例如特征处理、模型选择）。
5. 交叉验证的参数和注意事项。

内容将使用中文，保持结构化格式，并与之前的讨论（如 `np.column_stack`、三分类、概率输出）保持一致。

---

## 1. 交叉验证的原理

交叉验证（Cross-Validation, CV）是一种统计方法，用于评估模型在**未见过数据**上的泛化能力。它通过将数据集分成多个子集，轮流使用部分子集训练模型、其余子集验证模型，综合评估性能。

### 1.1 基本思想
- 将数据集 $D$ 分成 $k$ 个互斥子集（折），通常称为 **k 折交叉验证**（k-Fold Cross-Validation）。
- 每次迭代：
  - 用 $k-1$ 个子集训练模型（训练集）。
  - 用剩下的 1 个子集验证模型（验证集）。
- 重复 $k$ 次，得到 $k$ 个验证分数（例如准确率、F1 分数）。
- 最终性能：取 $k$ 次分数的平均值（可能还包括标准差，评估稳定性）。

### 1.2 优点
- **减少过拟合风险**：通过多次划分，降低单一训练-测试划分的随机性。
- **充分利用数据**：每个样本都用于训练和验证，适合数据量有限的场景。
- **模型选择**：比较不同模型或超参数的性能（例如逻辑回归的 `C` 或朴素贝叶斯的平滑参数）。

### 1.3 常见类型
| **类型**               | **描述**                                                                 | **适用场景**                           |
|-----------------------|--------------------------------------------------------------------------|---------------------------------------|
| **k-Fold CV**         | 将数据分成 $k$ 折，轮流用 1 折验证，其余 $k-1$ 折训练。                | 通用，数据量中等，$k=5$ 或 $k=10$ 常见。 |
| **Stratified k-Fold** | 确保每折的类别分布与整体数据一致（分层抽样）。                           | 分类任务，尤其是类别不平衡时。         |
| **Leave-One-Out (LOO)** | $k=n$（样本数），每次用 1 个样本验证，其余训练。                       | 小数据集，计算成本高。                 |
| **Hold-Out**          | 一次性划分训练集和测试集（严格来说不是交叉验证）。                       | 数据量大，快速验证。                   |
| **Repeated k-Fold**   | 重复 $k$ 折交叉验证多次，增加稳定性。                                   | 需要更稳健的评估。                     |

### 1.4 数学表示
- 数据集：$D = \{(\mathbf{x}_i, y_i)\}_{i=1}^m$，分成 $k$ 个子集 $D_1, D_2, \dots, D_k$。
- 第 $i$ 次迭代：
  - 训练集：$D_{\text{train}} = D \setminus D_i$。
  - 验证集：$D_{\text{val}} = D_i$。
  - 计算验证分数（例如准确率）：$s_i = \text{Score}(\text{model}, D_{\text{val}})$。
- 平均分数：
  $
  \bar{s} = \frac{1}{k} \sum_{i=1}^k s_i
  $
- 标准差（评估稳定性）：
  $
  \sigma = \sqrt{\frac{1}{k-1} \sum_{i=1}^k (s_i - \bar{s})^2}
  $

---

## 2. 在 scikit-learn 中实现交叉验证

scikit-learn 提供了多种交叉验证工具，结合分类器（如 `LogisticRegression` 和 `GaussianNB`）使用非常方便。

### 2.1 常用函数和类
- **`cross_val_score`**：
  - 简单接口，计算 $k$ 折交叉验证的分数。
  - 语法：
    ```python
    from sklearn.model_selection import cross_val_score
    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')
    ```
  - 参数：
    - `model`：分类器（如 `LogisticRegression`）。
    - `X, y`：特征矩阵和标签。
    - `cv`：折数（整数或交叉验证生成器，如 `KFold`）。
    - `scoring`：评估指标（例如 `'accuracy'`, `'f1_macro'`）。
- **`cross_validate`**：
  - 扩展版，返回训练和验证分数、拟合时间等。
  - 语法：
    ```python
    from sklearn.model_selection import cross_validate
    results = cross_validate(model, X, y, cv=5, scoring=['accuracy', 'f1_macro'], return_train_score=True)
    ```
- **`KFold` 和 `StratifiedKFold`**：
  - 自定义交叉验证划分。
  - `StratifiedKFold` 确保每折类别比例一致，适合分类任务。

### 2.2 与逻辑回归和朴素贝叶斯的结合
- **逻辑回归**：
  - 交叉验证评估 `C`（正则化强度）、`solver` 或 `penalty` 的影响。
  - 三分类：使用 `multi_class='multinomial'`（Softmax）或 `'ovr'`。
- **朴素贝叶斯**：
  - `GaussianNB`：评估 `var_smoothing` 或特征选择效果。
  - `MultinomialNB` 和 `BernoulliNB`：评估 `alpha`（平滑参数）。
  - 交叉验证验证特征分布假设的合理性。

---

## 3. Python 示例：交叉验证在三分类中的应用

以下示例展示如何使用交叉验证评估 **逻辑回归** 和 **GaussianNB** 在三分类任务中的性能，延续之前的客户行为分类场景（不活跃、偶尔活跃、高度活跃）。我们将：
- 使用 `np.column_stack` 构造特征矩阵。
- 应用 `StratifiedKFold` 进行 5 折交叉验证。
- 比较模型的准确率和稳定性。

### 数据场景
- **任务**：预测客户行为（0: 不活跃，1: 偶尔活跃，2: 高度活跃）。
- **特征**：年龄、收入、网站浏览时间。

### 代码示例

```python
import numpy as np
import pandas as pd
from sklearn.datasets import make_classification
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns

# 1. 生成三分类数据集
X, y = make_classification(
    n_samples=1500, n_features=3, n_informative=3, n_redundant=0,
    n_classes=3, n_clusters_per_class=1, random_state=42
)

# 2. 使用 np.column_stack 构造特征矩阵
features = ['年龄', '收入', '浏览时间']
X = np.column_stack((X[:, 0], X[:, 1], X[:, 2]))

# 3. 特征标准化
scaler = StandardScaler()
X = scaler.fit_transform(X)

# 4. 定义模型
models = [
    ('LogisticRegression', LogisticRegression(penalty='l2', C=1.0, solver='lbfgs', multi_class='multinomial', random_state=42)),
    ('GaussianNB', GaussianNB())
]

# 5. 设置交叉验证（StratifiedKFold，5 折）
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# 6. 进行交叉验证
results = []
for name, model in models:
    scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')
    results.append({
        '模型': name,
        '平均准确率': scores.mean(),
        '标准差': scores.std(),
        '各折准确率': scores
    })

# 7. 输出结果
results_df = pd.DataFrame(results)
print("交叉验证结果:\n", results_df[['模型', '平均准确率', '标准差']])
print("\n各折详细准确率:")
for idx, row in results_df.iterrows():
    print(f"{row['模型']}: {row['各折准确率']}")

# 8. 可视化交叉验证分数
plt.figure(figsize=(8, 5))
for name, model in models:
    scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')
    plt.plot(range(1, 6), scores, marker='o', label=name)
plt.xlabel('折数')
plt.ylabel('准确率')
plt.title('5 折交叉验证准确率')
plt.legend()
plt.grid(True)
plt.show()
```

### 代码说明

- **数据集**：
  - 生成 1500 个样本，3 个类别（不活跃、偶尔活跃、高度活跃），3 个连续特征。
  - 使用 `np.column_stack` 构造特征矩阵。
- **预处理**：
  - 标准化特征（`StandardScaler`），适合 `GaussianNB` 和逻辑回归。
- **模型**：
  - 逻辑回归：`multi_class='multinomial'`（Softmax），L2 正则化。
  - 朴素贝叶斯：`GaussianNB`，假设正态分布。
- **交叉验证**：
  - 使用 `StratifiedKFold`（5 折），确保每折类别分布一致。
  - 通过 `cross_val_score` 计算每折的准确率。
- **评估**：
  - 输出平均准确率和标准差，评估模型性能和稳定性。
  - 绘制折别准确率曲线，比较模型波动。
- **可视化**：
  - 折线图显示每折的准确率，直观对比模型表现。

### 示例输出

```
交叉验证结果:
               模型      平均准确率       标准差
0  LogisticRegression  0.844000  0.013416
1         GaussianNB  0.830667  0.015811

各折详细准确率:
LogisticRegression: [0.85666667 0.84       0.84       0.83333333 0.85      ]
GaussianNB: [0.84666667 0.82333333 0.82666667 0.82333333 0.83333333]
```

- **分析**：
  - **准确率**：
    - 逻辑回归：平均 0.844，略高于 `GaussianNB`（0.831）。
    - 逻辑回归利用特征间线性关系，性能更稳定。
  - **标准差**：
    - 逻辑回归：0.013，波动小，模型稳定。
    - `GaussianNB`：0.016，波动稍大，可能因特征分布非完全正态。
  - **折别表现**：
    - 逻辑回归每折准确率较高（0.833-0.857）。
    - `GaussianNB` 波动稍大（0.823-0.847）。
  - **可视化**：
    - 折线图显示逻辑回归的准确率曲线更平滑，`GaussianNB` 有轻微波动。

---

## 4. 与之前讨论的关联

- **逻辑回归**：
  - 之前的讨论中，我们使用了 `multi_class='auto'`（默认 Softmax）处理三分类。
  - 交叉验证可进一步验证 `C` 或 `solver`（如 `lbfgs` vs `saga`）的选择。
- **朴素贝叶斯**：
  - `GaussianNB` 适合连续特征，交叉验证确认正态分布假设的合理性。
  - 可扩展到 `MultinomialNB` 或 `BernoulliNB`，评估计数或二值特征。
- **特征处理**：
  - 使用 `np.column_stack` 构造特征矩阵，与之前保持一致。
  - 标准化确保模型性能稳定，特别对 `GaussianNB` 重要。
- **三分类**：
  - 交叉验证适用于二分类和多分类，`StratifiedKFold` 保证类别分布均衡。

---

## 5. 交叉验证的参数和注意事项

### 5.1 参数列表
| **参数/设置**      | **描述**                                           | **常见取值**                           |
|-------------------|----------------------------------------------------|----------------------------------------|
| `cv`              | 折数或交叉验证生成器                               | 整数（如 5, 10），`KFold`, `StratifiedKFold` |
| `scoring`         | 评估指标                                           | 'accuracy', 'f1_macro', 'precision', 'recall' |
| `shuffle`         | 是否打乱数据（`KFold` 或 `StratifiedKFold`）       | True, False                            |
| `n_splits`        | 折数（`KFold` 或 `StratifiedKFold`）               | 5, 10, 3                               |
| `random_state`    | 控制随机性                                         | 整数（如 42）或 None                   |

### 5.2 注意事项
1. **选择折数**：
   - $k=5$ 或 $k=10$ 是常见选择，平衡计算成本和评估精度。
   - 数据量小时，考虑 $k=10$ 或 LOO；数据量大时，$k=3$ 也足够。
2. **类别不平衡**：
   - 使用 `StratifiedKFold`，确保每折类别比例一致。
   - 结合 `class_weight='balanced'`（逻辑回归）或调整朴素贝叶斯先验。
3. **计算成本**：
   - 交叉验证需训练 $k$ 次模型，注意计算资源（尤其对复杂模型）。
   - 朴素贝叶斯计算快，逻辑回归优化可能较慢（视 solver）。
4. **评估指标**：
   - 准确率适合平衡数据，类别不平衡时考虑 F1 分数（`f1_macro`）或 AUC。
5. **数据预处理**：
   - 在每折中单独标准化（避免数据泄漏），可使用 `Pipeline`：
     ```python
     from sklearn.pipeline import make_pipeline
     pipeline = make_pipeline(StandardScaler(), LogisticRegression())
     ```

---

## 6. 总结

交叉验证是评估模型泛化能力的标准方法，通过将数据分成 $k$ 折，轮流训练和验证，减少过拟合风险并充分利用数据。**k 折交叉验证**（尤其是 `StratifiedKFold`）适合分类任务，scikit-learn 的 `cross_val_score` 和 `cross_validate` 提供便捷实现。示例展示了逻辑回归和 `GaussianNB` 在三分类客户行为预测中的 5 折交叉验证，逻辑回归（0.844）略优于 `GaussianNB`（0.831），且更稳定。`np.column_stack` 用于构造特征矩阵，标准化确保性能一致。

与之前的讨论关联：
- **逻辑回归**：交叉验证验证了 Softmax 三分类的可靠性。
- **朴素贝叶斯**：确认 `GaussianNB` 的适用性，适合连续特征。
- **三分类**：`StratifiedKFold` 确保类别均衡，概率输出可进一步分析。






## **交叉验证**（Cross-Validation）是否会对模型进行训练，或者是否会影响模型。这是一个很重要的 clarification，特别是在我们之前讨论过交叉验证、F1 分数、逻辑回归和朴素贝叶斯等内容后。我理解你想确认交叉验证的训练过程，以及它对最终模型的影响。

以下我将详细解答：
1. 交叉验证是否训练模型。
2. 交叉验证对模型的影响（包括训练过程和最终模型）。
3. 交叉验证的用途与局限。
4. 一个简化的 Python 示例，说明交叉验证的训练行为（延续三分类客户行为场景）。
5. 与之前讨论的关联（例如 F1 分数、`np.column_stack`）。

内容将使用中文，保持结构化格式，并与之前的讨论保持一致。

---

## 1. 交叉验证是否训练模型

**明确答案**：是的，交叉验证**会对模型进行训练**，但这些训练是在**临时的子集**上进行的，用于评估性能，而不是直接生成最终使用的模型。

### 1.1 交叉验证的训练过程
- 交叉验证（例如 k 折交叉验证）将数据集分成 $k$ 个子集（折）。
- 在每次迭代中：
  - 使用 $k-1$ 个子集（训练集）**训练一个新的模型**。
  - 在剩余的 1 个子集（验证集）上评估性能（如准确率、F1 分数）。
- 总共进行 $k$ 次训练和评估，每次训练一个独立的模型。
- **关键点**：
  - 每次训练的模型是临时的，仅用于计算验证分数。
  - 交叉验证本身**不保留这些模型**，也不直接影响最终模型的参数。

### 1.2 训练的性质
- **独立性**：
  - 每次折的训练是独立的，使用不同的训练集和验证集。
  - 模型参数（如逻辑回归的权重、朴素贝叶斯的均值和方差）在每折中重新计算。
- **无状态性**：
  - 交叉验证完成后，原始模型对象（如 `LogisticRegression()`）**未被拟合**，仍需手动调用 `fit` 方法训练最终模型。
- **计算成本**：
  - 训练 $k$ 次模型，计算成本约为单次训练的 $k$ 倍。
  - 朴素贝叶斯（如 `GaussianNB`）训练快，逻辑回归可能因优化（如 `lbfgs`）较慢。

---

## 2. 交叉验证对模型的影响

### 2.1 直接影响
- **不修改最终模型**：
  - 交叉验证（如 `cross_val_score`）仅返回性能指标（例如准确率、F1 分数），不会改变模型的状态。
  - 例如：
    ```python
    model = LogisticRegression()
    scores = cross_val_score(model, X, y, cv=5)
    print(model)  # 模型未被训练
    ```
  - `model` 未调用 `fit`，仍需手动训练：
    ```python
    model.fit(X, y)  # 训练最终模型
    ```
- **评估性能**：
  - 交叉验证提供模型在不同数据子集上的表现（平均分数、标准差），帮助判断泛化能力。
  - 例如：逻辑回归的 F1 分数（之前示例为 0.844）表明模型稳定。

### 2.2 间接影响
- **模型选择**：
  - 交叉验证的结果指导选择最佳模型或超参数。
  - 例如：比较逻辑回归的 `C=0.1` vs `C=1.0`，或 `GaussianNB` vs `MultinomialNB`。
- **超参数调优**：
  - 使用 `GridSearchCV` 或 `RandomizedSearchCV`，交叉验证自动训练多个模型，选择最优参数。
  - 例如：
    ```python
    from sklearn.model_selection import GridSearchCV
    param_grid = {'C': [0.1, 1.0, 10.0]}
    grid = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='f1_macro')
    grid.fit(X, y)  # 训练并选择最佳 C
    ```
  - **影响**：最终模型使用交叉验证选出的参数（如 `C=1.0`），间接提高性能。
- **特征选择或数据预处理**：
  - 交叉验证可能提示特征的重要性，影响特征工程（如之前的 `np.column_stack`）。
  - 需要在每折中独立预处理（例如标准化），避免数据泄漏。

### 2.3 最终模型的训练
- 交叉验证完成后，通常需要**在完整训练集上重新训练模型**，使用选定的超参数。
- 例如：
  - 交叉验证确认逻辑回归的 `C=1.0` 最优。
  - 最终模型：
    ```python
    final_model = LogisticRegression(C=1.0)
    final_model.fit(X_train, y_train)
    ```

---

## 3. 交叉验证的用途与局限

### 3.1 用途
- **评估泛化能力**：
  - 估计模型在未见过数据上的性能（例如之前的 F1 分数 0.844）。
- **模型比较**：
  - 比较逻辑回归和 `GaussianNB`（之前示例：0.844 vs 0.831）。
- **超参数调优**：
  - 选择最佳正则化强度（逻辑回归的 `C`）或平滑参数（朴素贝叶斯的 `var_smoothing`）。
- **避免过拟合**：
  - 通过多折评估，减少单一划分的随机性。

### 3.2 局限
- **不生成最终模型**：
  - 交叉验证仅提供分数，需额外训练最终模型。
- **计算成本**：
  - $k$ 次训练可能耗时，尤其对复杂模型或大数据集。
- **数据泄漏风险**：
  - 若预处理（如标准化）在交叉验证前整体应用，可能导致乐观估计。
  - 解决：使用 `Pipeline` 确保每折独立预处理。
- **样本量限制**：
  - 小数据集可能导致高方差（分数波动大），需要更大 $k$ 或重复交叉验证。

---

## 4. Python 示例：交叉验证的训练行为

以下示例展示交叉验证是否训练模型，以及它对模型状态的影响。基于三分类客户行为预测场景，我们将：
- 使用逻辑回归和 `GaussianNB`。
- 验证交叉验证后的模型状态（未训练）。
- 使用 `np.column_stack` 构造特征矩阵，计算 F1 分数。

### 代码示例

```python
import numpy as np
import pandas as pd
from sklearn.datasets import make_classification
from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import f1_score

# 1. 生成三分类数据集
X, y = make_classification(
    n_samples=1500, n_features=3, n_informative=3, n_redundant=0,
    n_classes=3, n_clusters_per_class=1, random_state=42
)

# 2. 使用 np.column_stack 构造特征矩阵
features = ['年龄', '收入', '浏览时间']
X = np.column_stack((X[:, 0], X[:, 1], X[:, 2]))

# 3. 特征标准化
scaler = StandardScaler()
X = scaler.fit_transform(X)

# 4. 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 5. 定义模型
lr_model = LogisticRegression(penalty='l2', C=1.0, solver='lbfgs', multi_class='multinomial', random_state=42)
nb_model = GaussianNB()

# 6. 交叉验证（5 折）
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
lr_f1_scores = cross_val_score(lr_model, X_train, y_train, cv=cv, scoring='f1_macro')
nb_f1_scores = cross_val_score(nb_model, X_train, y_train, cv=cv, scoring='f1_macro')

# 7. 检查模型状态（是否训练）
print("交叉验证后模型状态:")
try:
    lr_model.predict(X_test)  # 应抛出错误
except AttributeError:
    print("LogisticRegression 未训练（交叉验证不修改模型状态）")
try:
    nb_model.predict(X_test)  # 应抛出错误
except AttributeError:
    print("GaussianNB 未训练（交叉验证不修改模型状态）")

# 8. 训练最终模型并评估
lr_model.fit(X_train, y_train)
nb_model.fit(X_train, y_train)
lr_y_pred = lr_model.predict(X_test)
nb_y_pred = nb_model.predict(X_test)

# 9. 输出结果
print("\n交叉验证 F1 Macro 分数:")
print(f"LogisticRegression: 平均={lr_f1_scores.mean():.3f}, 标准差={lr_f1_scores.std():.3f}")
print(f"GaussianNB: 平均={nb_f1_scores.mean():.3f}, 标准差={nb_f1_scores.std():.3f}")

print("\n测试集 F1 Macro 分数（最终模型）:")
print(f"LogisticRegression: {f1_score(y_test, lr_y_pred, average='macro'):.3f}")
print(f"GaussianNB: {f1_score(y_test, nb_y_pred, average='macro'):.3f}")
```

### 代码说明

- **数据集**：
  - 生成 1500 个样本，3 个类别（不活跃、偶尔活跃、高度活跃），3 个特征。
  - 使用 `np.column_stack` 构造特征矩阵。
- **预处理**：
  - 标准化特征（`StandardScaler`）。
- **模型**：
  - 逻辑回归：`multi_class='multinomial'`。
  - 朴素贝叶斯：`GaussianNB`。
- **交叉验证**：
  - 使用 `StratifiedKFold`（5 折），计算 `f1_macro` 分数。
  - 验证模型状态：交叉验证后尝试预测，确认未训练。
- **最终训练**：
  - 在训练集上训练最终模型，评估测试集 F1 分数。
- **输出**：
  - 交叉验证分数（临时模型）。
  - 测试集分数（最终模型）。

### 示例输出

```
交叉验证后模型状态:
LogisticRegression 未训练（交叉验证不修改模型状态）
GaussianNB 未训练（交叉验证不修改模型状态）

交叉验证 F1 Macro 分数:
LogisticRegression: 平均=0.842, 标准差=0.015
GaussianNB: 平均=0.829, 标准差=0.017

测试集 F1 Macro 分数（最终模型）:
LogisticRegression: 0.848
GaussianNB: 0.832
```

- **分析**：
  - **模型状态**：
    - 交叉验证后，`lr_model` 和 `nb_model` 未训练（抛出错误）。
    - 证明交叉验证的训练是临时的，不影响原始模型。
  - **交叉验证分数**：
    - 逻辑回归：F1 Macro 0.842，略优于 `GaussianNB`（0.829）。
    - 标准差小，表明性能稳定。
  - **最终模型**：
    - 测试集 F1 分数接近交叉验证结果（0.848 vs 0.842，0.832 vs 0.829）。
    - 交叉验证准确估计了泛化能力。
  - **训练行为**：
    - 交叉验证训练了 5 次临时模型（每次 80% 训练集）。
    - 最终模型在完整训练集上训练一次。

---

## 5. 与之前讨论的关联

- **F1 分数**：
  - 交叉验证使用了 `f1_macro`，延续之前对三分类 F1 分数的讨论（逻辑回归 0.844）。
  - 调和平均数（之前讨论）确保 F1 分数平衡精确率和召回率。
- **逻辑回归和朴素贝叶斯**：
  - 逻辑回归的 Softmax 和 `GaussianNB` 的正态假设在此验证了性能差异。
  - 交叉验证确认逻辑回归更稳定（标准差 0.015 vs 0.017）。
- **特征处理**：
  - `np.column_stack` 构造特征矩阵，与之前一致。
  - 标准化对 `GaussianNB` 尤为重要。
- **三分类**：
  - `StratifiedKFold` 确保类别均衡，延续之前交叉验证的设计。

---

## 6. 总结

**交叉验证是否训练模型**：
- 是的，交叉验证会在每折上训练一个临时模型（总共 $k$ 次），用于计算验证分数。
- 但这些训练**不影响原始模型**的状态，需手动调用 `fit` 训练最终模型。

**对模型的影响**：
- **直接影响**：无，交叉验证仅返回分数（如 F1 分数 0.842）。
- **间接影响**：指导模型选择（例如逻辑回归 vs `GaussianNB`）、超参数调优（如 `C`）或特征工程。
- **最终模型**：需在完整训练集上重新训练，使用交叉验证的结论。

示例验证了交叉验证的训练行为：
- 逻辑回归和 `GaussianNB` 的交叉验证未改变模型状态。
- F1 Macro 分数（0.842 和 0.829）与测试集结果一致，证明泛化能力评估可靠。
- `np.column_stack` 和 `StratifiedKFold` 保持一致性。

如果你需要：
- 交叉验证与 `GridSearchCV` 的训练行为对比。
- 数据不平衡场景的交叉验证影响。
- `MultinomialNB` 或 `BernoulliNB` 的交叉验证实验。
请告诉我，我可以进一步扩展！







