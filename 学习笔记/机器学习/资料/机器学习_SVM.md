æ”¯æŒå‘é‡æœºï¼ˆSupport Vector Machine, SVMï¼‰æ˜¯ä¸€ç§å¼ºå¤§çš„ç›‘ç£å­¦ä¹ ç®—æ³•ï¼Œå¹¿æ³›ç”¨äºåˆ†ç±»ï¼ˆSVCï¼‰å’Œå›å½’ï¼ˆSVRï¼‰ä»»åŠ¡ã€‚ä»¥ä¸‹æ˜¯å¯¹ SVM åŸç†çš„è¯¦ç»†è¯´æ˜ï¼Œé‡ç‚¹ä»‹ç»å…¶æ ¸å¿ƒæ¦‚å¿µã€æ•°å­¦åŸºç¡€å’Œå›å½’ä»»åŠ¡ï¼ˆSVRï¼‰åœ¨ `load_diabetes` æ•°æ®é›†ä¸­çš„åº”ç”¨èƒŒæ™¯ã€‚ç”±äºä½ ä¹‹å‰æåˆ°å­¦ä¹ æ›²çº¿ã€RidgeCVã€æœ´ç´ è´å¶æ–¯ç­‰ï¼Œæˆ‘ä¼šä»¥æ¸…æ™°ã€ç®€æ´çš„æ–¹å¼è§£é‡Š SVM åŸç†ï¼Œå¹¶ä¸å›å½’ä»»åŠ¡è”ç³»èµ·æ¥ã€‚

### 1. SVM åŸç†æ¦‚è¿°
SVM çš„æ ¸å¿ƒç›®æ ‡æ˜¯æ‰¾åˆ°ä¸€ä¸ª**æœ€ä¼˜è¶…å¹³é¢**ï¼Œç”¨äºåˆ†ç±»æˆ–å›å½’ï¼š
- **åˆ†ç±»ï¼ˆSVCï¼‰**ï¼šæ‰¾åˆ°ä¸€ä¸ªè¶…å¹³é¢ï¼Œä½¿å…¶ä¸æœ€è¿‘çš„æ•°æ®ç‚¹ï¼ˆæ”¯æŒå‘é‡ï¼‰ä¹‹é—´çš„è·ç¦»ï¼ˆè¾¹ç•Œï¼Œmarginï¼‰æœ€å¤§åŒ–ï¼Œä»è€Œå®ç° robust çš„åˆ†ç±»ã€‚
- **å›å½’ï¼ˆSVRï¼‰**ï¼šæ‰¾åˆ°ä¸€ä¸ªå‡½æ•°ï¼Œä½¿é¢„æµ‹å€¼ä¸çœŸå®å€¼çš„åå·®ä¸è¶…è¿‡ä¸€ä¸ªé˜ˆå€¼ $\epsilon$ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹å¹³æ»‘ï¼ˆæœ€å¤§åŒ–è¾¹ç•Œï¼‰ã€‚

SVM çš„ä¼˜åŠ¿åœ¨äºï¼š
- é€šè¿‡æ ¸æŠ€å·§ï¼ˆKernel Trickï¼‰å¤„ç†éçº¿æ€§æ•°æ®ã€‚
- å¯¹é«˜ç»´æ•°æ®å’Œå°æ•°æ®é›†è¡¨ç°è‰¯å¥½ã€‚
- é€šè¿‡æ­£åˆ™åŒ–å‚æ•°ï¼ˆå¦‚ $C$ï¼‰å¹³è¡¡æ¨¡å‹å¤æ‚åº¦å’Œé”™è¯¯ã€‚

### 2. SVM åˆ†ç±»ï¼ˆSVCï¼‰åŸç†
#### 2.1 æ ¸å¿ƒæ¦‚å¿µ
- **è¶…å¹³é¢**ï¼šåœ¨ $n$ ç»´ç©ºé—´ä¸­ï¼Œåˆ†ç±»è¶…å¹³é¢å®šä¹‰ä¸º $ \mathbf{w}^T \mathbf{x} + b = 0 $ï¼Œå…¶ä¸­ $\mathbf{w}$ æ˜¯æ³•å‘é‡ï¼Œ$b$ æ˜¯æˆªè·ã€‚
- **æ”¯æŒå‘é‡**ï¼šè·ç¦»è¶…å¹³é¢æœ€è¿‘çš„æ•°æ®ç‚¹ï¼Œå†³å®šè¾¹ç•Œä½ç½®ã€‚
- **æœ€å¤§è¾¹ç•Œ**ï¼šSVM ä¼˜åŒ–ç›®æ ‡æ˜¯æœ€å¤§åŒ–è¾¹ç•Œå®½åº¦ï¼Œå³ $ \frac{2}{||\mathbf{w}||} $ã€‚
- **ç¡¬è¾¹ç•Œ vs è½¯è¾¹ç•Œ**ï¼š
  - ç¡¬è¾¹ç•Œï¼šè¦æ±‚æ‰€æœ‰æ•°æ®ç‚¹è¢«æ­£ç¡®åˆ†ç±»ï¼ˆä»…é™çº¿æ€§å¯åˆ†ï¼‰ã€‚
  - è½¯è¾¹ç•Œï¼šå…è®¸ä¸€å®šè¯¯åˆ†ç±»ï¼Œé€šè¿‡æ­£åˆ™åŒ–å‚æ•° $C$ æ§åˆ¶è¯¯åˆ†ç±»æƒ©ç½šã€‚

#### 2.2 æ•°å­¦ä¼˜åŒ–
ä¼˜åŒ–ç›®æ ‡æ˜¯ï¼š
$
\min_{\mathbf{w}, b} \frac{1}{2} ||\mathbf{w}||^2 + C \sum_{i=1}^n \xi_i
$
çº¦æŸæ¡ä»¶ï¼š
$
y_i (\mathbf{w}^T \mathbf{x}_i + b) \geq 1 - \xi_i, \quad \xi_i \geq 0, \quad \forall i
$
- $\frac{1}{2} ||\mathbf{w}||^2$ï¼šæœ€å°åŒ–æ³•å‘é‡èŒƒæ•°ï¼Œæœ€å¤§åŒ–è¾¹ç•Œã€‚
- $C \sum \xi_i$ï¼šæƒ©ç½šè¯¯åˆ†ç±»ï¼Œ$\xi_i$ æ˜¯æ¾å¼›å˜é‡ï¼Œ$C$ æ§åˆ¶æ­£åˆ™åŒ–å¼ºåº¦ã€‚
- é€šè¿‡æ‹‰æ ¼æœ—æ—¥å¯¹å¶é—®é¢˜æ±‚è§£ï¼Œå¼•å…¥æ ¸å‡½æ•°å¤„ç†éçº¿æ€§ã€‚

#### 2.3 æ ¸æŠ€å·§
å¯¹äºéçº¿æ€§å¯åˆ†æ•°æ®ï¼ŒSVM ä½¿ç”¨æ ¸å‡½æ•°å°†æ•°æ®æ˜ å°„åˆ°é«˜ç»´ç©ºé—´ï¼š
- å¸¸ç”¨æ ¸å‡½æ•°ï¼š
  - çº¿æ€§æ ¸ï¼š$ K(\mathbf{x}_i, \mathbf{x}_j) = \mathbf{x}_i^T \mathbf{x}_j $
  - å¾„å‘åŸºå‡½æ•°ï¼ˆRBFï¼‰æ ¸ï¼š$ K(\mathbf{x}_i, \mathbf{x}_j) = \exp(-\gamma ||\mathbf{x}_i - \mathbf{x}_j||^2) $
  - å¤šé¡¹å¼æ ¸ï¼š$ K(\mathbf{x}_i, \mathbf{x}_j) = (\mathbf{x}_i^T \mathbf{x}_j + c)^d $
- æ ¸å‡½æ•°é¿å…æ˜¾å¼è®¡ç®—é«˜ç»´æ˜ å°„ï¼Œæé«˜è®¡ç®—æ•ˆç‡ã€‚

### 3. æ”¯æŒå‘é‡å›å½’ï¼ˆSVRï¼‰åŸç†
SVR æ˜¯ SVM çš„å›å½’ç‰ˆæœ¬ï¼Œé€‚ç”¨äº `load_diabetes` æ•°æ®é›†çš„è¿ç»­ç›®æ ‡é¢„æµ‹ã€‚

#### 3.1 æ ¸å¿ƒæ¦‚å¿µ
- **ç›®æ ‡**ï¼šæ‰¾åˆ°ä¸€ä¸ªå‡½æ•° $ f(\mathbf{x}) = \mathbf{w}^T \mathbf{x} + b $ï¼Œä½¿é¢„æµ‹å€¼ $ f(\mathbf{x}_i) $ ä¸çœŸå®å€¼ $ y_i $ çš„åå·®ä¸è¶…è¿‡ $\epsilon$ï¼ŒåŒæ—¶ä¿æŒå‡½æ•°å¹³æ»‘ï¼ˆæœ€å°åŒ– $||\mathbf{w}||$ï¼‰ã€‚
- **$\epsilon$-ç®¡é“**ï¼šé¢„æµ‹å€¼åœ¨çœŸå®å€¼ $\pm \epsilon$ èŒƒå›´å†…ä¸è®¡å…¥æŸå¤±ã€‚
- **æ”¯æŒå‘é‡**ï¼šè½åœ¨ $\epsilon$-ç®¡é“è¾¹ç•Œä¸Šæˆ–ä¹‹å¤–çš„æ•°æ®ç‚¹ï¼Œå†³å®šå›å½’å‡½æ•°ã€‚

#### 3.2 æ•°å­¦ä¼˜åŒ–
ä¼˜åŒ–ç›®æ ‡ï¼š
$
\min_{\mathbf{w}, b} \frac{1}{2} ||\mathbf{w}||^2 + C \sum_{i=1}^n (\xi_i + \xi_i^*)
$
çº¦æŸæ¡ä»¶ï¼š
$
y_i - (\mathbf{w}^T \mathbf{x}_i + b) \leq \epsilon + \xi_i, \quad (\mathbf{w}^T \mathbf{x}_i + b) - y_i \leq \epsilon + \xi_i^*, \quad \xi_i, \xi_i^* \geq 0
$
- $\frac{1}{2} ||\mathbf{w}||^2$ï¼šæœ€å°åŒ–æ³•å‘é‡èŒƒæ•°ï¼Œä¿æŒå‡½æ•°å¹³æ»‘ã€‚
- $C \sum (\xi_i + \xi_i^*)$ï¼šæƒ©ç½šè¶…å‡º $\epsilon$-ç®¡é“çš„åå·®ï¼Œ$\xi_i, \xi_i^*$ æ˜¯ä¸Šä¸‹æ¾å¼›å˜é‡ã€‚
- $C$ï¼šæ§åˆ¶åå·®æƒ©ç½šï¼Œè¶Šå¤§è¶Šä¸¥æ ¼ã€‚
- $\epsilon$ï¼šç®¡é“å®½åº¦ï¼Œæ§åˆ¶å…è®¸çš„åå·®èŒƒå›´ã€‚

#### 3.3 æ ¸å‡½æ•°
ä¸ SVC ç±»ä¼¼ï¼ŒSVR ä½¿ç”¨æ ¸å‡½æ•°å¤„ç†éçº¿æ€§å›å½’é—®é¢˜ï¼Œå¸¸ç”¨ RBF æ ¸ï¼ˆå¦‚ä¹‹å‰ä»£ç ä¸­çš„ `kernel='rbf'`ï¼‰ã€‚

### 4. SVR åœ¨ `load_diabetes` æ•°æ®é›†ä¸­çš„åº”ç”¨
- **æ•°æ®é›†**ï¼š`load_diabetes` åŒ…å« 442 ä¸ªæ ·æœ¬ï¼Œ10 ä¸ªç‰¹å¾ï¼ˆå¦‚å¹´é¾„ã€BMIï¼‰ï¼Œç›®æ ‡æ˜¯ç–¾ç—…è¿›å±•çš„è¿ç»­å€¼ã€‚
- **SVR é€‚ç”¨æ€§**ï¼šSVR é€‚åˆä¸­å°è§„æ¨¡æ•°æ®é›†ï¼Œé€šè¿‡ RBF æ ¸æ•æ‰ç‰¹å¾ä¸ç›®æ ‡çš„éçº¿æ€§å…³ç³»ã€‚
- **å‚æ•°è°ƒä¼˜**ï¼š
  - `C`ï¼šå¹³è¡¡æ¨¡å‹å¤æ‚åº¦å’Œè¯¯å·®ï¼Œéœ€é€šè¿‡äº¤å‰éªŒè¯ä¼˜åŒ–ã€‚
  - `epsilon`ï¼šæ§åˆ¶ç®¡é“å®½åº¦ï¼Œå½±å“æ”¯æŒå‘é‡æ•°é‡ã€‚
  - `gamma`ï¼ˆRBF æ ¸ï¼‰ï¼šæ§åˆ¶æ ¸å‡½æ•°çš„å®½åº¦ï¼Œå½±å“æ¨¡å‹çµæ´»æ€§ã€‚

### 5. å­¦ä¹ æ›²çº¿ä¸­çš„ä½“ç°
åœ¨ä¹‹å‰çš„ SVR å­¦ä¹ æ›²çº¿ä»£ç ä¸­ï¼š
- **é«˜æ–¹å·®**ï¼šè®­ç»ƒé›† MSE ä½ã€éªŒè¯é›† MSE é«˜ï¼Œè¯´æ˜è¿‡æ‹Ÿåˆï¼ˆå¯èƒ½ $C$ è¿‡å¤§æˆ– $\epsilon$ è¿‡å°ï¼‰ã€‚
- **é«˜åå·®**ï¼šè®­ç»ƒé›†å’ŒéªŒè¯é›† MSE å‡é«˜ï¼Œè¯´æ˜æ¬ æ‹Ÿåˆï¼ˆå¯èƒ½æ¨¡å‹å¤ªç®€å•æˆ– $\epsilon$ è¿‡å¤§ï¼‰ã€‚
- å­¦ä¹ æ›²çº¿é€šè¿‡å¢åŠ æ ·æœ¬é‡ï¼Œè§‚å¯Ÿ MSE æ”¶æ•›æƒ…å†µï¼Œå¸®åŠ©è°ƒæ•´å‚æ•°ã€‚

### 6. ä¸å…¶ä»–æ¨¡å‹çš„å¯¹æ¯”
ç»“åˆä½ ä¹‹å‰çš„é—®é¢˜ï¼š
- **æœ´ç´ è´å¶æ–¯**ï¼šé€‚ç”¨äºåˆ†ç±»ï¼Œå‡è®¾ç‰¹å¾æ¡ä»¶ç‹¬ç«‹ï¼Œè®¡ç®—ç®€å•ä½†ä¸é€‚åˆå›å½’ä»»åŠ¡ï¼ˆå¦‚ `load_diabetes`ï¼‰ã€‚
- **Ridge å›å½’**ï¼šçº¿æ€§æ¨¡å‹ï¼Œé€šè¿‡ L2 æ­£åˆ™åŒ–æ§åˆ¶è¿‡æ‹Ÿåˆï¼Œé€‚åˆçº¿æ€§å…³ç³»ï¼Œä½†å¯¹éçº¿æ€§æ•°æ®è¡¨ç°ä¸å¦‚ SVRã€‚
- **SVR**ï¼šé€šè¿‡æ ¸å‡½æ•°å¤„ç†éçº¿æ€§å…³ç³»ï¼Œé€‚åˆå¤æ‚æ•°æ®ï¼Œä½†è®¡ç®—æˆæœ¬è¾ƒé«˜ï¼Œéœ€è°ƒä¼˜å¤šä¸ªå‚æ•°ã€‚

### 7. æ”¹è¿›å­¦ä¹ æ›²çº¿ä»£ç ï¼ˆå¯é€‰ï¼‰
å¦‚æœä½ æƒ³è¿›ä¸€æ­¥åˆ†æ SVR çš„åŸç†ï¼Œå¯ä»¥ä¿®æ”¹ä¹‹å‰çš„å­¦ä¹ æ›²çº¿ä»£ç ï¼Œæ·»åŠ å‚æ•°è°ƒä¼˜ï¼ˆå¦‚ç½‘æ ¼æœç´¢ä¼˜åŒ– `C` å’Œ `epsilon`ï¼‰ï¼š

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_diabetes
from sklearn.svm import SVR
from sklearn.model_selection import learning_curve, GridSearchCV
from sklearn.preprocessing import StandardScaler

# åŠ è½½æ•°æ®
diabetes = load_diabetes()
X, y = diabetes.data, diabetes.target

# æ ‡å‡†åŒ–ç‰¹å¾
scaler = StandardScaler()
X = scaler.fit_transform(X)

# ç½‘æ ¼æœç´¢ä¼˜åŒ– SVR å‚æ•°
param_grid = {'C': [0.1, 1, 10], 'epsilon': [0.01, 0.1, 0.5]}
grid = GridSearchCV(SVR(kernel='rbf'), param_grid, cv=5, scoring='neg_mean_squared_error')
grid.fit(X, y)
best_svr = grid.best_estimator_
print(f"æœ€ä¼˜å‚æ•°: {grid.best_params_}")

# è®¡ç®—å­¦ä¹ æ›²çº¿
train_sizes = np.linspace(0.1, 1.0, 10)
train_sizes, train_scores, valid_scores = learning_curve(
    best_svr, X, y, train_sizes=train_sizes, cv=5, scoring="neg_mean_squared_error", n_jobs=-1
)

# è½¬æ¢ä¸º MSE
train_mse = -train_scores.mean(axis=1)
valid_mse = -valid_scores.mean(axis=1)
train_mse_std = train_scores.std(axis=1)
valid_mse_std = valid_scores.std(axis=1)

# è‡ªç”±å¸ƒå±€å¯è§†åŒ–
fig = plt.figure(figsize=(8, 6))
ax = fig.add_axes([0.15, 0.15, 0.75, 0.75])
ax.plot(train_sizes, train_mse, 'b-', label='è®­ç»ƒé›† MSE')
ax.plot(train_sizes, valid_mse, 'r-', label='éªŒè¯é›† MSE')
ax.fill_between(train_sizes, train_mse - train_mse_std, train_mse + train_mse_std, color='blue', alpha=0.1)
ax.fill_between(train_sizes, valid_mse - valid_mse_std, valid_mse + valid_mse_std, color='red', alpha=0.1)
ax.set_xlabel('è®­ç»ƒæ ·æœ¬æ•°')
ax.set_ylabel('å‡æ–¹è¯¯å·® (MSE)')
ax.set_title(f'SVR å­¦ä¹ æ›²çº¿ (C={best_svr.C}, Îµ={best_svr.epsilon})')
ax.legend()
ax.grid(True, which="both", ls="--")

plt.show()
```

### 8. æ€»ç»“
- **SVM åŸç†**ï¼š
  - åˆ†ç±»ï¼šæœ€å¤§åŒ–è¾¹ç•Œè¶…å¹³é¢ï¼Œè½¯è¾¹ç•Œé€šè¿‡ $C$ æƒ©ç½šè¯¯åˆ†ç±»ã€‚
  - å›å½’ï¼šæœ€å°åŒ– $||\mathbf{w}||$ å’Œè¶…å‡º $\epsilon$-ç®¡é“çš„åå·®ï¼Œæ ¸å‡½æ•°å¤„ç†éçº¿æ€§ã€‚
- **SVR åœ¨ `load_diabetes` ä¸­çš„åº”ç”¨**ï¼šé€šè¿‡ RBF æ ¸æ•æ‰éçº¿æ€§å…³ç³»ï¼Œéœ€æ ‡å‡†åŒ–æ•°æ®å’Œè°ƒä¼˜å‚æ•°ã€‚
- **ä¸ä¹‹å‰è®¨è®ºçš„å…³ç³»**ï¼š
  - ç›¸æ¯”æœ´ç´ è´å¶æ–¯ï¼ŒSVR é€‚åˆå›å½’ä»»åŠ¡ï¼Œå¤„ç†å¤æ‚å…³ç³»ã€‚
  - ç›¸æ¯” Ridgeï¼ŒSVR é€šè¿‡æ ¸å‡½æ•°æ›´çµæ´»ï¼Œä½†è®¡ç®—æˆæœ¬é«˜ã€‚
  - å­¦ä¹ æ›²çº¿å¸®åŠ©è¯„ä¼° SVR çš„è¿‡æ‹Ÿåˆ/æ¬ æ‹Ÿåˆæƒ…å†µã€‚
- **å¯è§†åŒ–**ï¼šè‡ªç”±å¸ƒå±€æ¸…æ™°å±•ç¤ºå­¦ä¹ æ›²çº¿ï¼Œé€‚åˆå•ä¸€åˆ†æï¼Œç½‘æ ¼å¸ƒå±€å¯ç”¨äºå¤šæ¨¡å‹å¯¹æ¯”ã€‚

SVMï¼ˆæ”¯æŒå‘é‡æœºï¼‰ä¸­çš„ **RBF æ ¸å‡½æ•°**ï¼Œå³**å¾„å‘åŸºå‡½æ•°æ ¸**ï¼ˆRadial Basis Function kernelï¼‰ï¼Œæ˜¯ä¸€ç§å¸¸ç”¨çš„æ ¸å‡½æ•°ï¼Œå°¤å…¶é€‚ç”¨äºéçº¿æ€§åˆ†ç±»é—®é¢˜ã€‚

---

### ğŸ“Œ 1. RBFæ ¸å‡½æ•°å®šä¹‰

RBFæ ¸çš„æ•°å­¦è¡¨è¾¾å¼ä¸ºï¼š

\[
K(x_i, x_j) = \exp\left( -\gamma \|x_i - x_j\|^2 \right)
\]

- $ x_i, x_j $ï¼šè¾“å…¥ç‰¹å¾å‘é‡
- $ \|x_i - x_j\|^2 $ï¼šæ¬§å‡ é‡Œå¾—è·ç¦»çš„å¹³æ–¹
- $ \gamma > 0 $ï¼šè¶…å‚æ•°ï¼Œæ§åˆ¶è·ç¦»çš„å½±å“èŒƒå›´ï¼ˆå¸¸ä¸ `C` ä¸€èµ·è°ƒå‚ï¼‰

---

### ğŸ“Š 2. RBFæ ¸çš„ç›´è§‚ç†è§£

- å®ƒè¡¡é‡çš„æ˜¯ï¼šä¸¤ä¸ªæ ·æœ¬ç‚¹ä¹‹é—´è·ç¦»è¶Šå°ï¼Œå†…ç§¯ç»“æœ $ K $ è¶Šæ¥è¿‘ 1ï¼›è·ç¦»è¶Šè¿œï¼Œ$ K $ è¶Šæ¥è¿‘ 0ã€‚
- ç›¸å½“äºåœ¨åŸå§‹ç‰¹å¾ç©ºé—´ä¸­ï¼Œå°†æ ·æœ¬æŠ•å½±åˆ°ä¸€ä¸ªé«˜ç»´çš„æ— é™ç»´ç©ºé—´ï¼Œéçº¿æ€§åœ°åˆ†éš”æ•°æ®ã€‚

---

### ğŸ› ï¸ 3. è¶…å‚æ•°è¯´æ˜

- `C`: æƒ©ç½šé¡¹ç³»æ•°ï¼ˆæ§åˆ¶è¯¯å·®å®¹å¿åº¦ï¼Œè¶Šå¤§è¶Šä¸å®¹å¿è¯¯å·®ï¼‰
- `Î³ (gamma)`: æ§åˆ¶ä¸€ä¸ªæ ·æœ¬çš„å½±å“èŒƒå›´ï¼Œè¶Šå¤§å½±å“èŒƒå›´è¶Šå°ï¼ˆå¯èƒ½ä¼šè¿‡æ‹Ÿåˆï¼‰

> é€šå¸¸ç”¨ `np.logspace` æ¥å¯¹ `C` å’Œ `gamma` åšå‚æ•°æœç´¢ã€‚

---

### âœ… 4. scikit-learn ç¤ºä¾‹

```python
from sklearn import svm, datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# åŠ è½½æ•°æ®
iris = datasets.load_iris()
X = iris.data[:, :2]  # åªå–ä¸¤ä¸ªç‰¹å¾æ–¹ä¾¿ç”»å›¾
y = iris.target

# è®­ç»ƒé›†åˆ’åˆ†
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)

# æ ‡å‡†åŒ–
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# è®­ç»ƒ SVM with RBF kernel
clf = svm.SVC(kernel='rbf', C=1.0, gamma=0.5)
clf.fit(X_train, y_train)
```

---

### ğŸ¯ 5. ä½¿ç”¨åœºæ™¯

- æ•°æ®ç‰¹å¾ä¹‹é—´æ²¡æœ‰æ˜æ˜¾çº¿æ€§è¾¹ç•Œï¼›
- å¸Œæœ›è‡ªåŠ¨æ‰¾åˆ°ä¸€ä¸ªéçº¿æ€§å†³ç­–è¾¹ç•Œï¼›
- é€šå¸¸æ¯”çº¿æ€§æ ¸ï¼ˆlinearï¼‰åœ¨å®é™…åœºæ™¯ä¸­è¡¨ç°æ›´å¼ºã€‚

---

åœ¨ SVM ä¸­ï¼Œ**åŸå§‹æ¨¡å‹å¹¶ä¸ç›´æ¥è¾“å‡ºç½®ä¿¡æ¦‚ç‡**ï¼Œå› ä¸ºå®ƒæœ¬è´¨æ˜¯ä¸€ä¸ª**è¾¹ç•Œåˆ†ç±»å™¨**ï¼Œåªå‘Šè¯‰ä½ æ ·æœ¬åœ¨åˆ†ç•Œçº¿å“ªä¸€ä¾§ï¼Œè€Œä¸æ˜¯å±äºæŸä¸€ç±»çš„æ¦‚ç‡ã€‚

---

## âœ… 1. å¦‚ä½•è·å¾— SVM çš„ç½®ä¿¡æ¦‚ç‡ï¼ˆ`predict_proba`ï¼‰ï¼Ÿ

åœ¨ `scikit-learn` ä¸­ï¼Œå¯ä»¥é€šè¿‡è®¾ç½® `probability=True` æ¥å¼€å¯ **æ¦‚ç‡ä¼°è®¡**ï¼š

```python
from sklearn import svm

clf = svm.SVC(kernel='rbf', probability=True)
clf.fit(X_train, y_train)

# è·å–ç±»åˆ«æ¦‚ç‡ï¼ˆæ¯ä¸€è¡Œæ˜¯å±äºå„ç±»åˆ«çš„æ¦‚ç‡ï¼‰
probs = clf.predict_proba(X_test)
```

---

## ğŸ” 2. èƒŒååŸç†ï¼šPlatt Scaling

SVM çš„æ¦‚ç‡ä¼°è®¡æ˜¯é€šè¿‡ä¸€ç§ç§°ä¸º **Platt Scaling** çš„æ–¹æ³•åå¤„ç†å¾—åˆ°çš„ï¼š

\[
P(y=1 | x) = \frac{1}{1 + \exp(A f(x) + B)}
\]

- $ f(x) $ï¼šSVM çš„å†³ç­–å‡½æ•°ï¼ˆåˆ°è¾¹ç•Œçš„è·ç¦»ï¼‰
- $ A, B $ï¼šé€šè¿‡äº¤å‰éªŒè¯æ‹Ÿåˆå‡ºçš„å‚æ•°ï¼ˆç”¨å¯¹æ•°å‡ ç‡æ‹Ÿåˆï¼‰

è¿™æ˜¯ä¸€ç§**é€»è¾‘å›å½’æ‹Ÿåˆ SVM åˆ†æ•°**çš„æ–¹å¼ï¼Œæ‰€ä»¥å¸¦æ¥çš„æ¦‚ç‡å¹¶ä¸å®Œå…¨å¯é ï¼Œä»…æ˜¯ä¸€ä¸ªåéªŒæ¦‚ç‡ä¼°è®¡ã€‚

---

## âš ï¸ 3. ä½¿ç”¨å»ºè®®

- `probability=True` ä¼šä½¿æ¨¡å‹è®­ç»ƒæ›´æ…¢ï¼ˆå› ä¸ºéœ€è¦é¢å¤–æ‹Ÿåˆä¸€ä¸ªé€»è¾‘å›å½’ï¼‰
- å¦‚æœä½ éœ€è¦åšæ¨¡å‹é›†æˆã€é˜ˆå€¼è°ƒæ•´ï¼ˆå¦‚ F1 ä¼˜åŒ–ï¼‰ï¼Œæ¨èå¼€å¯

---

## ğŸ¯ 4. å¯è§†åŒ–ç¤ºä¾‹ï¼ˆäºŒç»´å¹³é¢ï¼‰

ä½ å¯ä»¥ç”»å‡ºå¸¦ç­‰é«˜çº¿çš„æ¦‚ç‡å›¾ï¼Œæ¯”å¦‚ä¸‹é¢è¿™ç§ï¼š

```python
import matplotlib.pyplot as plt
import numpy as np

# ç½‘æ ¼åˆ’åˆ†
xx, yy = np.meshgrid(np.linspace(-3, 3, 100), np.linspace(-3, 3, 100))
grid = np.c_[xx.ravel(), yy.ravel()]
probs = clf.predict_proba(grid)[:, 1].reshape(xx.shape)

# ç»˜å›¾
plt.contourf(xx, yy, probs, cmap="coolwarm", alpha=0.8)
plt.colorbar(label='P(class=1)')
```

---

éœ€è¦æˆ‘å¸®ä½ æŠŠå›¾ä¹Ÿç”»å‡ºæ¥çœ‹çœ‹å—ï¼Ÿæˆ–è€…ä½ æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œå¯ä»¥ä¸Šä¼ æˆ‘æ¥å¸®ä½ å¯è§†åŒ–ã€‚

